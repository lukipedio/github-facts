\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{report}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={GitHub Facts About the HDL Industry},
            pdfauthor={Lars Asplund; Unai Martinez-Corral},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[lmargin=35mm,rmargin=35mm]{geometry}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{biblatex}
\DeclarePrintbibliographyDefaults{heading=bibintoc}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\usepackage[]{biblatex}
\addbibresource{Rmd/refs.bib}

\title{GitHub Facts About the HDL Industry}
\author{Lars Asplund \and Unai Martinez-Corral}
\date{}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\listoffigures


\hypertarget{index}{%
\chapter{What Can GitHub Tell Us About the HDL Industry?}\label{index}}

\begin{center}\includegraphics[width=0.85\linewidth]{img/vhdl_adoption_by_region} \end{center}

During the last few years we've had many discussions within the \textbf{VUnit} community where we failed to reach a conclusion because we don't fully know how people at large are working with design and verification. Some questions arise frequently:

\begin{itemize}
\tightlist
\item
  How is verification done?
\item
  What frameworks are used? Are they used together?
\item
  What are the dominant coding styles? Would people align to those if they knew?
\end{itemize}

Knowing these would help the development of VUnit \autocite{vunit}; where do we put our efforts? do we add functionality or reuse functionality from others? where does it make sense to create tighter integrations with other tools? can we avoid spending time on endless indentation and casing discussions? Just let a tool fix it and move on.

It's not hard to find strong opinions in every possible direction, but we are looking for more solid facts. Facts can be found where data is, and one of the biggest pile of easy accessible data is GitHub. For that reason, this repository contains the mining effort to gather relevant information. Any information about projects related to HDL has been retrieved and processed.

In the first chapter of this series, verification practices are discussed.

\hypertarget{verification-practices}{%
\chapter{Verification Practices}\label{verification-practices}}

When it comes to statistical analysis of verification practices the \emph{Wilson Research Group functional verification study} \autocite{wilson14} \autocite{wilson16} \autocite{wilson18} has been the main source of information for many years. While this is a good effort towards highlighting interesting industry trends, it has a number of fundamental flaws:

\begin{itemize}
\tightlist
\item
  It includes some but not all of the \href{https://star-history.t9t.io/\#vunit/vunit\&osvvm/osvvm\&cocotb/cocotb\&UVVM/UVVM}{most popular} open-source verification frameworks: VUnit \autocite{vunit}, cocotb \autocite{cocotb}, OSVVM \autocite{osvvm} and UVVM \autocite{uvvm}.
\item
  Like any questionnaire-based study, it can't measure what people not responding do (\href{https://en.wikipedia.org/wiki/Participation_bias}{non-response bias}). By the same token, it can only measure what respondents say they do but not what they actually do (\href{https://en.wikipedia.org/wiki/Response_bias}{response bias}).
\item
  The data from the study in not open, only a selected set of views is. This means that conclusions outside of those views, for example regional differences, are difficult to draw.
\end{itemize}

Keeping the data private is probably the only way to get companies to participate in such a survey and herein lays the problem. \textbf{Facts}, from a scientific point of view, are based on \textbf{measurements} that can be \textbf{repeated} and \textbf{reviewed}. This is why this repository comprises a study of open source projects in Github, and the code used to collect and present data is open to everyone. The benefits of this approach are:

\begin{itemize}
\tightlist
\item
  All open-source verification frameworks are present.
\item
  There is no response bias, we see what people actually do. There can be other biases though, and we will get back to that.
\item
  Anyone can review and comment \href{https://github.com/LarsAsplund/github-facts/tree/main/py}{the code} in public.
\item
  Anyone can modify the code to create the views they are interested in.
\end{itemize}

One of the views we are interested in, is the VHDL view. Most VUnit users are working with VHDL designs and verification, so that will be the focus of our first analysis.

\hypertarget{repository-analysis}{%
\section{Repository Analysis}\label{repository-analysis}}

When scanning GitHub for VHDL repositories, about \textbf{1.9 million VHDL files} were found in \textbf{36000} repositories. These repositories were initially analyzed for two things:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Are tests provided?} This was a simple analysis just looking for VHDL files containing anything with \emph{test} or \emph{tb}.
\item
  \textbf{Are any of the standard frameworks used (VUnit, UVM, UVVM, OSVVM and/or cocotb)?} There have been discussions regarding the use of the term ``standard(ized)''; so, to be clear, we mean \emph{standard} as in well-established within the community, not as in standardized.
\end{enumerate}

The first analysis (see Figure \ref{fig:repositories}) revealed that roughly 44\% of all repositories provide tests for their code and that the trend is declining.

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{img/repositories_providing_tests} 

}

\caption{Repositories providing tests.}\label{fig:repositories}
\end{figure}

Just looking at the file names is not optimal. \textbf{6\% of the repositories using a standard VHDL-based framework (VUnit, UVVM or OSVVM) do not use such a naming convention}. However, it gives us a ballpark figure and a trend.

The second analysis (see Figure \ref{fig:standard}) looked at the repositories providing tests and calculated the percentage of them that are using at least one of the standard verification frameworks. This trend is increasing rapidly over the last few years.

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{img/repositories_using_std_framework} 

}

\caption{Repositories using standard frameworks.}\label{fig:standard}
\end{figure}

Look at the vertical axis though. While the trend is impressive, the absolute numbers are not. \textbf{Only 3\% of the repositories with tests created last year use a standard verification framework}.

This may come as a surprise. Many engineers working professionally with VHDL would probably say that verification is getting more and more important and that the majority is using a standard framework. Does this mean that GitHub data should be discarded as a relevent indicator for the professional world? There are at least three good reasons not to do so:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Our beliefs are based on our experiences, and our experiences are often based on our interactions with a limited group of people. This group of people may not be a good representation of the whole VHDL community, for example due to regional differences.
\item
  The tendency to only accept our own beliefs is called \href{https://en.wikipedia.org/wiki/Confirmation_bias}{confirmation bias} and is deeply rooted in the human nature. We need to be aware that it exists and try to look beyond it.
\item
  Not all GitHub repositories are developed by professionals, but some are. We cannot expect GitHub to be a perfect reflection of the professional world but we can expect signs from that world.
\end{enumerate}

In the following sections, we will dig deeper into the data to see what frameworks and combination of frameworks people are using. We will also compare those findings to the results presented in the \emph{Wilson Research Group functional verification study} \autocite{wilson18}.

\hypertarget{how-to}{%
\subsection{How-To}\label{how-to}}

The results presented so far were compiled using the scripts presented in the following sections.

\hypertarget{github-search}{%
\subsubsection{\texorpdfstring{\texttt{github\_search.py}}{github\_search.py}}\label{github-search}}

\href{https://github.com/LarsAsplund/github-facts/tree/main/py/github_search.py}{\texttt{github\_search.py}} is used to search GitHub for all repositories containing files of a specific language and matching a specified query. To find all repositories containing VHDL files one can specify \texttt{end} as the query since all VHDL files contain that key word. The result of the search is listed in text files stored in \texttt{result\_directory}. A GitHub user name and a Github \href{https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line}{access token} must also be provided to access the GitHub API.

\begin{verbatim}
python github_search.py \
  vhdl end result_directory \
  YourGitHubUser your_github_access_token
\end{verbatim}

The GitHub API has a number of restriction on searches. One is that you cannot get the full result of the search if the result contains more than 1000 files. To handle that, every search is further restricted by the script to only target files in a limited size range. First files between 1 - n bytes are searched where n is the largest number resulting in less than 1000 files, then files in a range starting with n + 1 bytes are searched and so on until the maximum searchable file size of 384 kB has been included. The accumulated search result after every such increment is stored in a separate file in \texttt{result\_directory} and only the last produced file contains the full result.

Occasionally there are more than 1000 found VHDL files of a single size, for example 264 bytes. In these cases some results are lost but most likely the repositories containing those missing files have other VHDL files caught in another search increment; so this will not have a significant effect on the overall statistics.

The GitHub API also has rate limitations, which means that searches with many results take a long time to complete. Searching for all VHDL files takes days but the more limited searches for specific verification frameworks that we will use later can complete in minutes. If you interrupt a longer search and restart it later \texttt{github\_search.py} will look at the intermediate result files in \texttt{result\_directory} and continue from where it was interrupted.

The result from the latest search for all VHDL files is found in \href{https://github.com/LarsAsplund/github-facts/tree/main/all_vhdl_repos.txt}{\texttt{all\_vhdl\_repos.txt}}

\hypertarget{github_clone.py}{%
\subsubsection{\texorpdfstring{\texttt{github\_clone.py}}{github\_clone.py}}\label{github_clone.py}}

\href{https://github.com/LarsAsplund/github-facts/tree/main/py/github_clone.py}{\texttt{github\_clone.py}} makes a clone of all repositories listed in a file such as those produced by \texttt{github\_search.py} (\ref{github-search}). The clone is sparse and only contains VHDL, SystemVerilog and Python files, which are the ones used for this study. The sparse clone is also stripped from its \texttt{.git} directory, and zipped to save storage space. The script also stores some basic information about the repository.

A call to the script looks like this:

\begin{verbatim}
python github_clone.py \
  repository_list result_directory \
  YourGitHubUser your_github_access_token
\end{verbatim}

If \texttt{repository\_list} contains a repository \texttt{foo/bar}, the script will create a directory \texttt{foo} under \texttt{result\_directory} and in that directory the zipped repository as \texttt{bar.zip}. The basic repository information is stored in a JSON file named \texttt{bar.basic.1.json}.

Cloning all VHDL repositories from GitHub takes several days and requires about 180 GB of storage. Due to that size, it has not been possible to share the data. Anyone interested in analyzing those repositories needs to recreate the data locally, using this script and the \href{https://github.com/LarsAsplund/github-facts/tree/main/all_vhdl_repos.txt}{all\_vhdl\_repos.txt} repository list.

\hypertarget{analyze-test-strategy}{%
\subsubsection{\texorpdfstring{\texttt{analyze\_test\_strategy.py}}{analyze\_test\_strategy.py}}\label{analyze-test-strategy}}

\href{https://github.com/LarsAsplund/github-facts/tree/main/py/analyze_test_strategy.py}{\texttt{analyze\_test\_strategy.py}} analyzes the cloned repositories and generates the statistics presented in this work. The initial search for repositories using any of the standard frameworks is automatic but also produces a number of false positives that must be removed manually:

\begin{itemize}
\tightlist
\item
  A repository with both VHDL and (System)Verilog files that is also using UVM or cocotb may not use these frameworks to verify the VHDL code. VUnit can also be used for (System)Verilog verification but the search script can distinguish and ignore such repositories to avoid false positives.
\item
  Sometimes the main design being verified is based on (System)Verilog but it also includes third party IPs written in VHDL. This is considered a false positive since the IPs are not the target for the verification and the design language of choice is not VHDL.
\item
  Some repositories have testbenches based on a standard framework but the purpose is not to verify VHDL code but rather to use the code for testing an EDA tool being developed. A parser for example.
\item
  This study is focused on the users of the frameworks, not the developers. The repositories hosting the frameworks and copies of these repositories have been excluded.
\end{itemize}

The false positives are listed in \href{https://github.com/LarsAsplund/github-facts/tree/main/fp_repos.json}{\texttt{fp\_repos.json}}.

The script will produce a JSON file for each analyzed repository (\texttt{repo\_name.test.2.json}) and also a summary JSON file. The name of that file is given in the call to the script

\begin{verbatim}
python analyze_test_strategy.py \
  path/to/directory/with/cloned/repositories \
  path/to/analysis_summary.json \
  --fp fp_repos.json
\end{verbatim}

\hypertarget{visualize_test_strategy.py}{%
\subsubsection{\texorpdfstring{\texttt{visualize\_test\_strategy.py}}{visualize\_test\_strategy.py}}\label{visualize_test_strategy.py}}

\href{https://github.com/LarsAsplund/github-facts/tree/main/py/visualize_test_strategy.py}{\texttt{visualize\_test\_strategy.py}} creates the figures used in this post from the results generated by \texttt{analyze\_test\_strategy.py} (\ref{analyze-test-strategy}). The figures are saved to the output directory given in the call.

\begin{verbatim}
python visualize_test_strategy.py \
  path/to/analysis_summary.json \
  path/to/output/directory
\end{verbatim}

\printbibliography[title=References]

\end{document}
